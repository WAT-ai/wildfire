{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b533c04",
   "metadata": {},
   "source": [
    "# Group weather data spatially and temporally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e09a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43126b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each year from 2016 to 2023\n",
    "for curr_year in range(2016, 2023):\n",
    "\n",
    "    # Define the base directory where the station data is located\n",
    "    base_dir = \"../data/processing/weather-stations/kelowna/\"\n",
    "\n",
    "    # Loop through each of the 36 fine areas\n",
    "    for i in range(1, 37):\n",
    "        # Read the CSV file for the current fine area\n",
    "        filtered_df = pd.read_csv(base_dir + f\"fine_area_{i}_stations.csv\")\n",
    "\n",
    "        # Define the columns of interest for filtering weather data\n",
    "        my_filter = ['ONE_DAY_PRECIPITATION', 'ONE_DAY_RAIN', 'MIN_TEMP', 'ONE_DAY_SNOW', 'time', 'MAX_TEMP']\n",
    "\n",
    "        # Loop through each week of the year (1 to 52)\n",
    "        for week in range(1, 53):\n",
    "            weekly_dataframes = []  # Initialize a list to store weekly dataframes\n",
    "\n",
    "            # Iterate through each row in the filtered station DataFrame\n",
    "            for index, row in filtered_df.iterrows():\n",
    "                network_name = row['Network Name']  # Get the network name for the station\n",
    "                native_id = row['Native ID']  # Get the native ID for the station\n",
    "\n",
    "                # Construct the file path for the weather data for the current week, network, and station\n",
    "                file_path = f'../data/raw/weather/{curr_year}/week_{week}/{network_name}/{native_id}.csv'\n",
    "\n",
    "                # Check if the weather data file exists for the current station and week\n",
    "                if os.path.exists(file_path):\n",
    "                    # Read the weather data CSV file and append it to the weekly dataframes list\n",
    "                    temp_df = pd.read_csv(file_path)\n",
    "                    weekly_dataframes.append(temp_df)\n",
    "                    \n",
    "            # If any dataframes were collected for the current week, combine them\n",
    "            if weekly_dataframes:\n",
    "                # Concatenate all the dataframes into a single DataFrame\n",
    "                combined_df = pd.concat(weekly_dataframes, ignore_index=True, axis=0, join='outer')\n",
    "                \n",
    "                # Check if the output directory for the current year and week exists, if not, create it\n",
    "                if not os.path.exists(f'../data/processing/final-weather/{curr_year}/week_{week}'):\n",
    "                    os.makedirs(f'../data/processing/final-weather/{curr_year}/week_{week}')\n",
    "                \n",
    "                # Define the file path to save the combined DataFrame as a CSV\n",
    "                combined_csv_path = f'../data/processing/final-weather/{curr_year}/week_{week}/fine_area_{i}_weather.csv'\n",
    "                \n",
    "                # Save the combined DataFrame to the defined CSV path\n",
    "                combined_df.to_csv(combined_csv_path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efbb16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
